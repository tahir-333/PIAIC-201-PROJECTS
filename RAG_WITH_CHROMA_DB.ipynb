{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tahir-333/PIAIC-201-PROJECTS/blob/main/RAG_WITH_CHROMA_DB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "edki1A111BmQ"
      },
      "source": [
        "# **KEY POINTS**\n",
        "* Instaling Google SDK\n",
        "* Configuring Google colab client with Google AI Studio (Where all AI models exist)\n",
        "* Checing all Google AI models\n",
        "* Selecting an embedding model for conversition of text into vectors\n",
        "* Checking vectors of text input and dimention of selected embedding model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4puEsiGZhCa"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq google-generativeai                     # Installing Google SDK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dSJeuzAcDf1"
      },
      "outputs": [],
      "source": [
        "# Connection of Client google colab with Google AI studio (all AI models exist here)\n",
        "\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "from google.colab import userdata\n",
        "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "T4J-gD7dcz6I",
        "outputId": "a1c246b6-4238-498d-b997-d76f2f9b47f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Model(name='models/chat-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 Chat (Legacy)',\n",
              "       description='A legacy text-only model optimized for chat conversations',\n",
              "       input_token_limit=4096,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
              "       temperature=0.25,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/text-bison-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='PaLM 2 (Legacy)',\n",
              "       description='A legacy model that understands text and generates text as an output',\n",
              "       input_token_limit=8196,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=None,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/embedding-gecko-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding Gecko',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=1024,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedText', 'countTextTokens'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/gemini-1.0-pro-vision-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-pro-vision',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.0 Pro Vision',\n",
              "       description=('The original Gemini 1.0 Pro Vision model version which was optimized for '\n",
              "                    'image understanding. Gemini 1.0 Pro Vision was deprecated on July 12, 2024. '\n",
              "                    'Move to a newer Gemini version.'),\n",
              "       input_token_limit=12288,\n",
              "       output_token_limit=4096,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.4,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=32),\n",
              " Model(name='models/gemini-1.5-pro-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Pro, our mid-size multimodal model that supports up to 2 '\n",
              "                    'million tokens.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro 001',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-pro-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Pro 002',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in September of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-pro',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Pro',\n",
              "       description=('Stable version of Gemini 1.5 Pro, our mid-size multimodal model that '\n",
              "                    'supports up to 2 million tokens, released in May of 2024.'),\n",
              "       input_token_limit=2000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash, our fast and versatile multimodal model for scaling '\n",
              "                    'across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash-001-tuning',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 001 Tuning',\n",
              "       description=('Version of Gemini 1.5 Flash that supports tuning, our fast and versatile '\n",
              "                    'multimodal model for scaling across diverse tasks, released in May of 2024.'),\n",
              "       input_token_limit=16384,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-1.5-flash',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Flash, our '\n",
              "                    'fast and versatile multimodal model for scaling across diverse tasks.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Gemini 1.5 Flash 002',\n",
              "       description=('Stable version of Gemini 1.5 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in September of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B 001',\n",
              "       description=('Stable version of Gemini 1.5 Flash-8B, our smallest and most cost effective '\n",
              "                    'Flash model, released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-latest',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash-8B Latest',\n",
              "       description=('Alias that points to the most recent production (non-experimental) release '\n",
              "                    'of Gemini 1.5 Flash-8B, our smallest and most cost effective Flash model, '\n",
              "                    'released in October of 2024.'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['createCachedContent', 'generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0827',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0827',\n",
              "       description=('Experimental release (August 27th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-1.5-flash-8b-exp-0924',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Gemini 1.5 Flash 8B Experimental 0924',\n",
              "       description=('Experimental release (September 24th, 2024) of Gemini 1.5 Flash-8B, our '\n",
              "                    'smallest and most cost effective Flash model. Replaced by '\n",
              "                    'Gemini-1.5-flash-8b-001 (stable).'),\n",
              "       input_token_limit=1000000,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Experimental',\n",
              "       description='Gemini 2.0 Flash Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens', 'bidiGenerateContent'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash',\n",
              "       description='Gemini 2.0 Flash',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash 001',\n",
              "       description=('Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model '\n",
              "                    'for scaling across diverse tasks, released in January of 2025.'),\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-001',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite 001',\n",
              "       description='Stable version of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash-Lite',\n",
              "       description='Gemini 2.0 Flash-Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview-02-05',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview 02-05',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-flash-lite-preview',\n",
              "       base_model_id='',\n",
              "       version='preview-02-05',\n",
              "       display_name='Gemini 2.0 Flash-Lite Preview',\n",
              "       description='Preview release (February 5th, 2025) of Gemini 2.0 Flash Lite',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=40),\n",
              " Model(name='models/gemini-2.0-pro-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Pro Experimental',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-pro-exp-02-05',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Pro Experimental 02-05',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-exp-1206',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini Experimental 1206',\n",
              "       description='Experimental release (February 5th, 2025) of Gemini 2.0 Pro',\n",
              "       input_token_limit=2097152,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-01-21',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp',\n",
              "       base_model_id='',\n",
              "       version='2.0-exp-01-21',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental 01-21',\n",
              "       description='Experimental release (January 21st, 2025) of Gemini 2.0 Flash Thinking',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/gemini-2.0-flash-thinking-exp-1219',\n",
              "       base_model_id='',\n",
              "       version='2.0',\n",
              "       display_name='Gemini 2.0 Flash Thinking Experimental',\n",
              "       description='Gemini 2.0 Flash Thinking Experimental',\n",
              "       input_token_limit=1048576,\n",
              "       output_token_limit=65536,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=0.7,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/learnlm-1.5-pro-experimental',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='LearnLM 1.5 Pro Experimental',\n",
              "       description=('Alias that points to the most recent stable version of Gemini 1.5 Pro, our '\n",
              "                    'mid-size multimodal model that supports up to 2 million tokens.'),\n",
              "       input_token_limit=32767,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['generateContent', 'countTokens'],\n",
              "       temperature=1.0,\n",
              "       max_temperature=2.0,\n",
              "       top_p=0.95,\n",
              "       top_k=64),\n",
              " Model(name='models/embedding-001',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Embedding 001',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/text-embedding-004',\n",
              "       base_model_id='',\n",
              "       version='004',\n",
              "       display_name='Text Embedding 004',\n",
              "       description='Obtain a distributed representation of a text.',\n",
              "       input_token_limit=2048,\n",
              "       output_token_limit=1,\n",
              "       supported_generation_methods=['embedContent'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None),\n",
              " Model(name='models/aqa',\n",
              "       base_model_id='',\n",
              "       version='001',\n",
              "       display_name='Model that performs Attributed Question Answering.',\n",
              "       description=('Model trained to return answers to questions that are grounded in provided '\n",
              "                    'sources, along with estimating answerable probability.'),\n",
              "       input_token_limit=7168,\n",
              "       output_token_limit=1024,\n",
              "       supported_generation_methods=['generateAnswer'],\n",
              "       temperature=0.2,\n",
              "       max_temperature=None,\n",
              "       top_p=1.0,\n",
              "       top_k=40),\n",
              " Model(name='models/imagen-3.0-generate-002',\n",
              "       base_model_id='',\n",
              "       version='002',\n",
              "       display_name='Imagen 3.0 002 model',\n",
              "       description='Vertex served Imagen 3.0 002 model',\n",
              "       input_token_limit=480,\n",
              "       output_token_limit=8192,\n",
              "       supported_generation_methods=['predict'],\n",
              "       temperature=None,\n",
              "       max_temperature=None,\n",
              "       top_p=None,\n",
              "       top_k=None)]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(genai.list_models())                          # list of AI models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "se_7KRL5mZxQ",
        "outputId": "c9798abe-9232-4c08-d691-cbedfae9d282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.027700976,\n",
              " 0.047637526,\n",
              " -0.036881845,\n",
              " 0.0008789616,\n",
              " -0.037119556,\n",
              " -0.0023898014,\n",
              " 0.021571813,\n",
              " 0.06512892,\n",
              " -0.0070468807,\n",
              " 0.0043520443,\n",
              " 0.036656868,\n",
              " -0.023544857,\n",
              " 0.09647634,\n",
              " -0.03162359,\n",
              " 0.01372836,\n",
              " -0.11184779,\n",
              " 0.009607273,\n",
              " 0.009218722,\n",
              " -0.08812401,\n",
              " -0.013613483,\n",
              " 0.0145730125,\n",
              " -0.0036260497,\n",
              " 0.05784887,\n",
              " -0.015007857,\n",
              " -0.008659887,\n",
              " 0.016321601,\n",
              " -0.004395524,\n",
              " -0.047357775,\n",
              " -0.013196754,\n",
              " -0.016362945,\n",
              " 0.07584969,\n",
              " 0.051054593,\n",
              " 0.011311344,\n",
              " -0.027413676,\n",
              " 0.060184903,\n",
              " 0.033739425,\n",
              " -0.0066259676,\n",
              " 0.061476335,\n",
              " 0.022556385,\n",
              " -0.033411756,\n",
              " -0.07054046,\n",
              " 0.02621096,\n",
              " -0.035783153,\n",
              " 0.054636523,\n",
              " -0.023849038,\n",
              " -0.03073361,\n",
              " -0.008869374,\n",
              " -0.0033394734,\n",
              " -0.02475675,\n",
              " 0.04735522,\n",
              " 0.025611218,\n",
              " 0.018156782,\n",
              " -0.031453747,\n",
              " 0.021517528,\n",
              " -0.020447819,\n",
              " -0.030643685,\n",
              " -0.009657613,\n",
              " -0.032844998,\n",
              " 0.057715803,\n",
              " -0.04759551,\n",
              " -0.023897205,\n",
              " -0.036312792,\n",
              " -0.025191203,\n",
              " -0.02121005,\n",
              " -0.0569868,\n",
              " 0.03472654,\n",
              " -0.0184042,\n",
              " 0.025744928,\n",
              " -0.08045995,\n",
              " 0.066155314,\n",
              " -0.009450883,\n",
              " 0.03792937,\n",
              " -0.02157536,\n",
              " 0.034539707,\n",
              " -0.0033336622,\n",
              " 0.02422724,\n",
              " 0.02383648,\n",
              " 0.0109670665,\n",
              " -0.048985694,\n",
              " 0.034618456,\n",
              " -0.030833064,\n",
              " 0.020344563,\n",
              " 0.068735465,\n",
              " 0.05738184,\n",
              " 0.0076917442,\n",
              " 0.004671365,\n",
              " -0.031351533,\n",
              " -0.023058182,\n",
              " -0.0770662,\n",
              " -0.00889064,\n",
              " 0.051038586,\n",
              " 0.03917848,\n",
              " 0.002980277,\n",
              " 0.041456215,\n",
              " 0.05688682,\n",
              " -0.0395801,\n",
              " -0.056672946,\n",
              " -0.085860334,\n",
              " 0.010797251,\n",
              " 0.068617865,\n",
              " 0.056819096,\n",
              " 0.0051956135,\n",
              " -6.2330887e-06,\n",
              " -0.04326112,\n",
              " 0.042810097,\n",
              " 0.088080905,\n",
              " -0.040361192,\n",
              " -0.03321073,\n",
              " -0.03799472,\n",
              " -0.014260993,\n",
              " 0.008618946,\n",
              " -0.07194561,\n",
              " 0.026828317,\n",
              " -0.05809817,\n",
              " 0.028439179,\n",
              " -0.08129617,\n",
              " -0.00027863175,\n",
              " 0.009191303,\n",
              " -0.014394066,\n",
              " -0.0027851118,\n",
              " 0.028941004,\n",
              " 0.059563555,\n",
              " 0.0031115965,\n",
              " 0.036102194,\n",
              " 0.06504506,\n",
              " -0.0026003635,\n",
              " 0.010807496,\n",
              " -0.05614815,\n",
              " -0.044414643,\n",
              " -0.025334965,\n",
              " 0.09949033,\n",
              " -0.10877613,\n",
              " -0.0025194404,\n",
              " 0.011336867,\n",
              " -0.033111814,\n",
              " 0.0030411624,\n",
              " 0.10116736,\n",
              " -0.002486477,\n",
              " 0.008551956,\n",
              " -0.005725251,\n",
              " 0.02300714,\n",
              " -0.016002348,\n",
              " -0.050032023,\n",
              " 0.024226453,\n",
              " 0.0185524,\n",
              " -0.036347333,\n",
              " 0.048903372,\n",
              " 0.011303015,\n",
              " -0.0651477,\n",
              " -0.010561838,\n",
              " -0.011424192,\n",
              " -0.024372876,\n",
              " 0.047531396,\n",
              " 0.010648424,\n",
              " -0.0046618874,\n",
              " 0.008508702,\n",
              " 0.065524876,\n",
              " -0.024053102,\n",
              " 0.0873156,\n",
              " -0.02531981,\n",
              " -0.011004834,\n",
              " -0.07832355,\n",
              " -0.03404224,\n",
              " -0.0049144183,\n",
              " -0.041281614,\n",
              " -0.028418139,\n",
              " 0.024584973,\n",
              " -0.049915142,\n",
              " 0.00097353995,\n",
              " 0.018298853,\n",
              " -0.0016436314,\n",
              " 0.009293771,\n",
              " -0.063706875,\n",
              " -0.029275328,\n",
              " -0.026597137,\n",
              " 0.019234912,\n",
              " -0.027080739,\n",
              " -0.010864811,\n",
              " -0.009804332,\n",
              " 0.03517361,\n",
              " 0.08856162,\n",
              " 0.040878575,\n",
              " -0.011035732,\n",
              " -0.07710363,\n",
              " 0.0014667226,\n",
              " -0.024922108,\n",
              " 0.006400949,\n",
              " 0.04746057,\n",
              " 0.04678217,\n",
              " 0.05650915,\n",
              " -0.05559971,\n",
              " 0.032816667,\n",
              " 0.0059525096,\n",
              " 0.036360845,\n",
              " 0.003254842,\n",
              " -0.04201807,\n",
              " 0.05499712,\n",
              " 0.0029551457,\n",
              " -0.054997742,\n",
              " -0.018575711,\n",
              " 0.0061114137,\n",
              " -0.02644547,\n",
              " -0.022077776,\n",
              " -0.04303292,\n",
              " 0.015993277,\n",
              " -0.007015712,\n",
              " -0.04219976,\n",
              " -0.04049588,\n",
              " 0.057540234,\n",
              " 0.012659814,\n",
              " -0.017675627,\n",
              " -0.009667927,\n",
              " 0.0006109087,\n",
              " -0.017944572,\n",
              " 0.045889597,\n",
              " 0.0271881,\n",
              " 0.067919366,\n",
              " -0.0059984326,\n",
              " 0.10300563,\n",
              " 0.024648711,\n",
              " -0.020048846,\n",
              " -0.020103125,\n",
              " -0.022324333,\n",
              " -0.009911787,\n",
              " -8.7000046e-07,\n",
              " 0.015824853,\n",
              " -0.025672413,\n",
              " -0.03724897,\n",
              " -0.009819986,\n",
              " -0.04066462,\n",
              " 0.00985529,\n",
              " -0.0032951455,\n",
              " 0.0078413,\n",
              " -0.012233995,\n",
              " -0.002724123,\n",
              " 0.022230223,\n",
              " -0.010691793,\n",
              " 0.028493026,\n",
              " -0.036827445,\n",
              " -0.02391986,\n",
              " 0.006707785,\n",
              " -0.0017157291,\n",
              " -0.021177884,\n",
              " 0.02351266,\n",
              " 0.07506594,\n",
              " 0.07684279,\n",
              " 0.029188067,\n",
              " 0.0671326,\n",
              " -0.014868151,\n",
              " -0.087951034,\n",
              " -0.024823822,\n",
              " -0.01770798,\n",
              " -0.05542431,\n",
              " -0.08091184,\n",
              " -0.022783237,\n",
              " -0.0236637,\n",
              " 0.030293066,\n",
              " -0.004122116,\n",
              " 0.011420322,\n",
              " -0.0072310367,\n",
              " 0.029672155,\n",
              " -0.07810685,\n",
              " -0.006691393,\n",
              " -0.029829768,\n",
              " -0.035706785,\n",
              " -0.060908873,\n",
              " -0.03235868,\n",
              " -0.041930657,\n",
              " 0.03862198,\n",
              " -0.06666414,\n",
              " 0.05600458,\n",
              " -0.019385051,\n",
              " -0.0024844697,\n",
              " -0.011264045,\n",
              " 0.04318634,\n",
              " 0.03615433,\n",
              " 0.01558654,\n",
              " 0.021310506,\n",
              " 0.027111184,\n",
              " -0.007854642,\n",
              " -0.0047951397,\n",
              " -0.036294725,\n",
              " -0.0010778973,\n",
              " -0.0035074472,\n",
              " 0.010650241,\n",
              " -0.06333213,\n",
              " -0.0025238246,\n",
              " 0.0032292793,\n",
              " -0.007986258,\n",
              " 0.017758243,\n",
              " 0.04774966,\n",
              " 0.04540244,\n",
              " 0.014525937,\n",
              " -0.048863433,\n",
              " 0.027424563,\n",
              " 0.017295491,\n",
              " 0.042902652,\n",
              " 0.023715079,\n",
              " 0.01470558,\n",
              " 0.009161892,\n",
              " 0.060441267,\n",
              " 0.053531703,\n",
              " -3.0709292e-05,\n",
              " 0.028938493,\n",
              " 0.016405227,\n",
              " 0.019110028,\n",
              " 0.058796056,\n",
              " -0.0460404,\n",
              " 0.02278142,\n",
              " -0.006701715,\n",
              " 0.0023431422,\n",
              " 0.018056244,\n",
              " -0.031076923,\n",
              " 0.02646092,\n",
              " -0.07945813,\n",
              " -0.026408276,\n",
              " -0.14275643,\n",
              " -0.022568861,\n",
              " -0.025965171,\n",
              " -0.018705575,\n",
              " -0.009358,\n",
              " 0.024986755,\n",
              " 0.020194596,\n",
              " -0.010622369,\n",
              " 0.06813932,\n",
              " -0.029940993,\n",
              " -0.027917547,\n",
              " 0.020307994,\n",
              " 0.00074414234,\n",
              " -0.019458935,\n",
              " 0.0032195281,\n",
              " 0.010032704,\n",
              " -0.0016410877,\n",
              " -0.04727619,\n",
              " 0.051365044,\n",
              " -0.009417356,\n",
              " -0.025198024,\n",
              " 0.041469477,\n",
              " 0.030170003,\n",
              " 0.04717967,\n",
              " -0.012580736,\n",
              " -0.002707906,\n",
              " 0.015092114,\n",
              " 0.017258825,\n",
              " 0.009579604,\n",
              " -0.03215586,\n",
              " -0.0025909888,\n",
              " -0.0081473375,\n",
              " 0.017187232,\n",
              " -0.0290661,\n",
              " 0.002151086,\n",
              " 0.054816835,\n",
              " 0.014348764,\n",
              " -0.0054422948,\n",
              " -0.0070604216,\n",
              " -0.018731145,\n",
              " 0.07915815,\n",
              " 0.032819554,\n",
              " 0.03657908,\n",
              " 0.010547284,\n",
              " -0.009460444,\n",
              " -0.019712798,\n",
              " -0.0060355733,\n",
              " -0.00792665,\n",
              " -0.01565602,\n",
              " -0.05062793,\n",
              " 0.014375362,\n",
              " 0.031026471,\n",
              " 0.018108223,\n",
              " -0.009369955,\n",
              " 0.043648247,\n",
              " -0.025619514,\n",
              " -0.006012977,\n",
              " 0.012027748,\n",
              " -0.0016434194,\n",
              " -0.017027538,\n",
              " -9.210621e-05,\n",
              " 0.032433283,\n",
              " 0.027937723,\n",
              " -0.059543643,\n",
              " -0.03933607,\n",
              " -0.022719894,\n",
              " -0.025921723,\n",
              " 0.0038315929,\n",
              " -0.061795752,\n",
              " 0.072757296,\n",
              " -0.026038678,\n",
              " -0.0026862381,\n",
              " 0.023870585,\n",
              " 0.027508996,\n",
              " -0.04010315,\n",
              " 0.038833503,\n",
              " 0.05516219,\n",
              " 0.0142870955,\n",
              " 0.018082853,\n",
              " 0.014682305,\n",
              " -0.043888632,\n",
              " 0.038322493,\n",
              " -0.0071318694,\n",
              " 0.053853575,\n",
              " -0.027084947,\n",
              " -0.042360213,\n",
              " 0.094686985,\n",
              " 0.011256053,\n",
              " -0.01624259,\n",
              " 0.007445258,\n",
              " 0.0735711,\n",
              " -0.0013658078,\n",
              " -0.010172327,\n",
              " -0.022838784,\n",
              " -0.033662137,\n",
              " 0.010737474,\n",
              " -0.015045408,\n",
              " 0.008727939,\n",
              " -0.0582032,\n",
              " -0.012219147,\n",
              " -0.021108923,\n",
              " 0.0062692333,\n",
              " -0.00379599,\n",
              " 0.036556087,\n",
              " -0.0028526846,\n",
              " -0.019692764,\n",
              " 0.010254392,\n",
              " -0.0063732704,\n",
              " 0.035069264,\n",
              " -0.070687875,\n",
              " -0.0026686967,\n",
              " 0.014455978,\n",
              " 0.019399676,\n",
              " 0.04613732,\n",
              " 0.044013176,\n",
              " -0.017958669,\n",
              " -0.008758824,\n",
              " 0.028527731,\n",
              " 0.037434183,\n",
              " 0.011537042,\n",
              " 0.0008511307,\n",
              " 0.020934356,\n",
              " -0.061615314,\n",
              " -0.022648629,\n",
              " -0.010069544,\n",
              " -0.029953621,\n",
              " -0.004391559,\n",
              " 0.053972505,\n",
              " -0.009961604,\n",
              " 0.0059127603,\n",
              " 0.036822744,\n",
              " 0.0081023555,\n",
              " -0.03764774,\n",
              " 0.018390931,\n",
              " -0.012185264,\n",
              " -0.004811536,\n",
              " -0.071910456,\n",
              " -0.02108875,\n",
              " -0.008685581,\n",
              " 0.0071931365,\n",
              " -0.024759462,\n",
              " -0.017262578,\n",
              " -0.040257588,\n",
              " 0.06758199,\n",
              " -0.02151895,\n",
              " -0.03467151,\n",
              " 0.058235392,\n",
              " 0.012187354,\n",
              " 0.023324497,\n",
              " -0.046556827,\n",
              " -0.03139024,\n",
              " 0.051536083,\n",
              " -0.025175095,\n",
              " 0.035354663,\n",
              " 0.055176,\n",
              " 0.006426937,\n",
              " 0.014132489,\n",
              " 0.0332132,\n",
              " -0.00967362,\n",
              " 0.011516512,\n",
              " 0.065388426,\n",
              " -0.034910556,\n",
              " -0.01790388,\n",
              " -0.023165181,\n",
              " -0.005791394,\n",
              " 0.025031725,\n",
              " -0.030519793,\n",
              " 0.047947314,\n",
              " 0.042263456,\n",
              " -0.023208031,\n",
              " -0.035485417,\n",
              " -0.018949531,\n",
              " 0.028676419,\n",
              " 0.024068031,\n",
              " 0.027177794,\n",
              " 0.025517542,\n",
              " -0.029871752,\n",
              " -0.073374666,\n",
              " 0.016476255,\n",
              " -0.009514118,\n",
              " 0.009591815,\n",
              " 0.015612685,\n",
              " 0.039265,\n",
              " 0.026993316,\n",
              " 0.08950458,\n",
              " -0.0040809466,\n",
              " -0.023792475,\n",
              " -0.011010243,\n",
              " -0.030980248,\n",
              " 0.016142396,\n",
              " -0.060622197,\n",
              " -0.045856748,\n",
              " 0.06346839,\n",
              " -0.010555544,\n",
              " 0.015048002,\n",
              " 0.0043789367,\n",
              " 0.009685456,\n",
              " -0.020402804,\n",
              " -0.04311503,\n",
              " 0.038611267,\n",
              " -0.016933434,\n",
              " 0.0468719,\n",
              " -0.0060841683,\n",
              " 0.071415864,\n",
              " -0.020777652,\n",
              " -0.025199383,\n",
              " 0.0037594694,\n",
              " 0.021749109,\n",
              " 0.0089035705,\n",
              " -0.0077452455,\n",
              " 0.02701661,\n",
              " 0.0039607612,\n",
              " -0.00046882164,\n",
              " -0.017874312,\n",
              " -0.028126305,\n",
              " 0.055129297,\n",
              " 0.02886422,\n",
              " 0.020788077,\n",
              " -0.011601207,\n",
              " 0.053859986,\n",
              " 0.023829678,\n",
              " 0.0138242645,\n",
              " 0.019560017,\n",
              " 0.017925803,\n",
              " 0.00885425,\n",
              " -0.00518342,\n",
              " 0.006045817,\n",
              " 0.015871072,\n",
              " 0.024384595,\n",
              " 0.0009788873,\n",
              " -0.044491727,\n",
              " 0.05193962,\n",
              " -0.028777778,\n",
              " 0.080690816,\n",
              " 0.022802884,\n",
              " -0.026941424,\n",
              " 0.023783457,\n",
              " 0.029852983,\n",
              " -0.0041488474,\n",
              " -0.023536265,\n",
              " 0.009959993,\n",
              " 0.016241793,\n",
              " -0.056182224,\n",
              " 0.018706027,\n",
              " -0.012336267,\n",
              " -0.008715043,\n",
              " 0.004732217,\n",
              " -0.02783507,\n",
              " -0.051131092,\n",
              " -0.037252624,\n",
              " 0.013754462,\n",
              " 0.007860551,\n",
              " -0.008514182,\n",
              " -0.020940898,\n",
              " -0.0058021303,\n",
              " -0.0096070925,\n",
              " -0.017145606,\n",
              " -0.025287786,\n",
              " 0.022040375,\n",
              " 0.017334573,\n",
              " -0.034425016,\n",
              " -0.007584992,\n",
              " 0.0300492,\n",
              " -0.031153236,\n",
              " 0.0619389,\n",
              " 0.0029313422,\n",
              " 0.052771058,\n",
              " 0.011200281,\n",
              " -0.012740074,\n",
              " -0.020823162,\n",
              " 0.028389689,\n",
              " 0.019736841,\n",
              " 0.0040551587,\n",
              " -0.00709914,\n",
              " -0.02644039,\n",
              " 0.060602117,\n",
              " 0.012432994,\n",
              " -0.041716535,\n",
              " -0.018600771,\n",
              " -0.021376729,\n",
              " -0.03693906,\n",
              " -0.020307394,\n",
              " 0.02383738,\n",
              " 0.0063754967,\n",
              " -0.0007609402,\n",
              " -0.009920104,\n",
              " 0.022646299,\n",
              " 0.023540214,\n",
              " -0.032438427,\n",
              " -0.10561698,\n",
              " -0.015835006,\n",
              " -0.030339379,\n",
              " -0.0025942945,\n",
              " 0.0028855745,\n",
              " 0.013606645,\n",
              " 0.04419476,\n",
              " -0.0524112,\n",
              " 0.07266598,\n",
              " -0.06696059,\n",
              " 0.017145399,\n",
              " 0.004174242,\n",
              " -0.026723832,\n",
              " 0.043644346,\n",
              " -0.026974093,\n",
              " -0.04083475,\n",
              " 0.015571753,\n",
              " 0.018767286,\n",
              " -0.017955413,\n",
              " -0.032993942,\n",
              " -0.003442882,\n",
              " -0.0060282624,\n",
              " 0.0031638981,\n",
              " -0.0038792777,\n",
              " 0.025295177,\n",
              " -0.04771561,\n",
              " 0.020533862,\n",
              " 0.055379722,\n",
              " -0.025714558,\n",
              " -0.0011735167,\n",
              " 0.012186587,\n",
              " 0.0088474015,\n",
              " -0.02881409,\n",
              " 0.037271697,\n",
              " 0.007817553,\n",
              " -0.019492999,\n",
              " 0.013027309,\n",
              " 0.04994646,\n",
              " 0.01994768,\n",
              " -0.04404291,\n",
              " 0.067077085,\n",
              " -0.04091939,\n",
              " -0.010422865,\n",
              " 0.05519535,\n",
              " 0.018224446,\n",
              " -0.03633386,\n",
              " -0.041769143,\n",
              " 0.04028726,\n",
              " -0.026638195,\n",
              " -0.01469354,\n",
              " 0.038373984,\n",
              " -0.031116307,\n",
              " -0.063621044,\n",
              " 0.0070549967,\n",
              " -0.055385064,\n",
              " -0.0060920003,\n",
              " -0.02956256,\n",
              " 0.041645892,\n",
              " 0.00380096,\n",
              " -0.030965047,\n",
              " 0.012463025,\n",
              " 0.03160518,\n",
              " 0.030890808,\n",
              " -0.02449895,\n",
              " -0.021846049,\n",
              " 0.007430044,\n",
              " 0.05058479,\n",
              " 0.04989923,\n",
              " 0.036167346,\n",
              " -0.032008473,\n",
              " 0.03181996,\n",
              " 0.012593055,\n",
              " -0.012185607,\n",
              " 0.0018219496,\n",
              " 0.029597571,\n",
              " 0.015688661,\n",
              " -0.015596441,\n",
              " -0.024741659,\n",
              " -0.06473784,\n",
              " 0.006480987,\n",
              " 0.02300961,\n",
              " 0.088853925,\n",
              " -0.049976118,\n",
              " -0.020210655,\n",
              " 0.0020627105,\n",
              " -0.038095497,\n",
              " -0.02917947,\n",
              " 0.024757145,\n",
              " 0.0035718526,\n",
              " 0.01461591,\n",
              " 0.03153195,\n",
              " -0.0470185,\n",
              " 0.050031062,\n",
              " -0.060531747,\n",
              " -0.06846234,\n",
              " -0.0034358501,\n",
              " -0.014536158,\n",
              " -0.052228075,\n",
              " 0.009906416,\n",
              " 0.038743224,\n",
              " -0.008827395,\n",
              " -0.0002465501,\n",
              " -0.0020223293,\n",
              " -0.07455355,\n",
              " 0.022742907,\n",
              " -0.007050395,\n",
              " 0.046194866,\n",
              " 0.03585693,\n",
              " 0.02043137,\n",
              " 0.0030249248,\n",
              " 0.030097976,\n",
              " -0.005735291,\n",
              " 0.01523795,\n",
              " 0.02075624,\n",
              " 0.029881142,\n",
              " -0.0037487631,\n",
              " -0.03956165,\n",
              " -0.009771995,\n",
              " 0.057246916,\n",
              " 0.009686142,\n",
              " -0.024965284,\n",
              " -0.07177024,\n",
              " 0.019983051,\n",
              " -0.0428993,\n",
              " 0.053851373,\n",
              " 0.061949365,\n",
              " 0.022120703,\n",
              " -0.03572084,\n",
              " 0.046583395,\n",
              " -0.022790829,\n",
              " -0.0252149,\n",
              " -0.022443455,\n",
              " 0.027242875,\n",
              " -0.006519436,\n",
              " -0.007025357,\n",
              " 0.06497635,\n",
              " -0.039334264,\n",
              " -0.046458147,\n",
              " -0.040961225,\n",
              " -0.023194572,\n",
              " -0.009808103,\n",
              " -0.052792437,\n",
              " -0.019367754,\n",
              " -0.05231507,\n",
              " -0.026331687,\n",
              " -0.07552343,\n",
              " 0.0017512493,\n",
              " 0.03561843,\n",
              " 0.070088334,\n",
              " 0.043936472,\n",
              " 0.0020755362,\n",
              " -0.012846994,\n",
              " -0.0031771883,\n",
              " 0.042634744,\n",
              " 0.055242073,\n",
              " -0.034016788,\n",
              " 0.017234076,\n",
              " -0.02338856,\n",
              " -0.011718921,\n",
              " -0.083783254,\n",
              " -0.0005030394,\n",
              " 0.012200264,\n",
              " -0.034166135]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from typing import Dict\n",
        "\n",
        "result: Dict = genai.embed_content(\n",
        "    model = \"models/text-embedding-004\",\n",
        "    content = \"What is he meaning of life\",\n",
        "    task_type= \"RETRIEVAL_DOCUMENT\",\n",
        "    title = \"Embedding of single string\"\n",
        ")\n",
        "result[\"embedding\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WTQuHU9rixH",
        "outputId": "0fdc1fc6-9d25-496b-fd54-a7de31a3f49e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(result[\"embedding\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "4JgOxwUYuS5J",
        "outputId": "087daa61-d1e7-442c-b632-7995e02ff3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.015756672, 0.032602023, -0.067666866, -0.032489877, -0.023135763] 768\n"
          ]
        }
      ],
      "source": [
        "from typing import Dict\n",
        "\n",
        "result: Dict = genai.embed_content(\n",
        "    model = \"models/text-embedding-004\",\n",
        "    content = [\"\"\"What is the meaning of Life?\n",
        "               Who can we become a true Muslim?\n",
        "               How does our brain work?\"\"\",\n",
        "               ],\n",
        "\n",
        "               task_type =\"RETRIEVAL_DOCUMENT\",\n",
        "               title = \"Embedding of a list of string\",\n",
        "\n",
        ")\n",
        "for v in result[\"embedding\"]:\n",
        "  print(v[:5], len(v))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Tq5viWw2eS6"
      },
      "source": [
        "# **WORKING WITH LANGCHAIN AND CHROMA DATABASE**\n",
        "* Installing necessary packages\n",
        "* Importing some modules\n",
        "* Saving some docs in vector database\n",
        "* Converting input text into vectors by embedding model\n",
        "* Exploring some vectorstore methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA9pLcZSa6hK"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wy4GYMt22lXl",
        "outputId": "385bd72c-1579-4812-dffe-dc48fd2eae44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m611.1/611.1 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m177.4/177.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m84.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m452.6/452.6 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -Uq langchain-chroma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvhkV_rV3d8E"
      },
      "outputs": [],
      "source": [
        "import getpass\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTyukKJr3k6C"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "\n",
        "document_1 = Document(\n",
        "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_2 = Document(\n",
        "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_3 = Document(\n",
        "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_4 = Document(\n",
        "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_5 = Document(\n",
        "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        ")\n",
        "\n",
        "document_6 = Document(\n",
        "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_7 = Document(\n",
        "    page_content=\"The top 10 soccer players in the world right now.\",\n",
        "    metadata={\"source\": \"website\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_8 = Document(\n",
        "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_9 = Document(\n",
        "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
        "    metadata={\"source\": \"news\"},\n",
        "\n",
        ")\n",
        "\n",
        "document_10 = Document(\n",
        "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
        "    metadata={\"source\": \"tweet\"},\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9iuQRI5sCcZw"
      },
      "outputs": [],
      "source": [
        "!pip install -Uq langchain-google-genai\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6SgqSGcgD8gJ"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "embeddings = GoogleGenerativeAIEmbeddings(\n",
        "    model = \"models/text-embedding-004\",\n",
        "    google_api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "cXPO8QR_EsQe",
        "outputId": "cfa855f2-b991-41cc-88d2-d6e22f43bc03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.017449533566832542,\n",
              " 0.00423057284206152,\n",
              " -0.01623031683266163,\n",
              " -0.016505029052495956,\n",
              " -0.06461256742477417,\n",
              " 0.01820499449968338,\n",
              " 0.016866469755768776,\n",
              " 0.01903708279132843,\n",
              " -0.029288399964571,\n",
              " 0.04391857609152794,\n",
              " -0.008509811945259571,\n",
              " -0.04573705047369003,\n",
              " 0.0642002522945404,\n",
              " -0.05801449343562126,\n",
              " -0.0005171262891963124,\n",
              " -0.08059146255254745,\n",
              " -0.04954610764980316,\n",
              " -0.005449499003589153,\n",
              " -0.07152819633483887,\n",
              " -0.05514032021164894,\n",
              " 0.06650283932685852,\n",
              " -0.002848941134288907,\n",
              " -0.002461489988490939,\n",
              " -0.029116535559296608,\n",
              " 0.019781287759542465,\n",
              " 0.01294338796287775,\n",
              " -0.030414380133152008,\n",
              " 0.01865960657596588,\n",
              " 0.0025111082941293716,\n",
              " -0.041915345937013626,\n",
              " 0.03056776523590088,\n",
              " 0.016028650104999542,\n",
              " 0.009318720549345016,\n",
              " 0.009597932919859886,\n",
              " 0.043503642082214355,\n",
              " -0.008322397246956825,\n",
              " -0.04214119538664818,\n",
              " 0.01727312244474888,\n",
              " -0.014516242779791355,\n",
              " -0.07920394092798233,\n",
              " -0.053394339978694916,\n",
              " 0.029943233355879784,\n",
              " 0.017272653058171272,\n",
              " 0.010020836256444454,\n",
              " 0.009401612915098667,\n",
              " -0.03466758131980896,\n",
              " -0.010123214684426785,\n",
              " 0.005233678966760635,\n",
              " -0.006129465065896511,\n",
              " 0.07962048798799515,\n",
              " 0.013797173276543617,\n",
              " -0.007822769694030285,\n",
              " -0.037285853177309036,\n",
              " 0.049142926931381226,\n",
              " -0.006837735418230295,\n",
              " -0.013196692802011967,\n",
              " -0.023904331028461456,\n",
              " -0.030700134113430977,\n",
              " 0.07672664523124695,\n",
              " -0.039733003824949265,\n",
              " -0.007699650712311268,\n",
              " 0.006892791483551264,\n",
              " 0.015485492534935474,\n",
              " -0.016309482976794243,\n",
              " -0.03136182576417923,\n",
              " 0.01873895525932312,\n",
              " -0.005303729325532913,\n",
              " 0.014411916956305504,\n",
              " -0.02674093283712864,\n",
              " 0.042142052203416824,\n",
              " 0.013990308158099651,\n",
              " 0.02058151364326477,\n",
              " -0.06444031745195389,\n",
              " 0.046937670558691025,\n",
              " -0.05184733867645264,\n",
              " 0.02842997945845127,\n",
              " -0.003855433315038681,\n",
              " -0.005789428483694792,\n",
              " -0.06212098151445389,\n",
              " 0.04009746015071869,\n",
              " -0.020364079624414444,\n",
              " 0.030580535531044006,\n",
              " 0.021776074543595314,\n",
              " 0.0437554307281971,\n",
              " 0.047897227108478546,\n",
              " 0.038030993193387985,\n",
              " -0.029711205512285233,\n",
              " -0.004899620544165373,\n",
              " -0.048479773104190826,\n",
              " -0.013572201132774353,\n",
              " 0.030422350391745567,\n",
              " 0.06202187389135361,\n",
              " -0.004117739386856556,\n",
              " -0.007878810167312622,\n",
              " 0.027989504858851433,\n",
              " 0.058266740292310715,\n",
              " -0.1319330334663391,\n",
              " -0.03823060169816017,\n",
              " 0.04546922817826271,\n",
              " -0.003769385162740946,\n",
              " -0.016273710876703262,\n",
              " 0.04451253265142441,\n",
              " 0.03810975328087807,\n",
              " -0.07033886015415192,\n",
              " 0.034380145370960236,\n",
              " 0.02470557764172554,\n",
              " 0.00808896217495203,\n",
              " -0.0017295515863224864,\n",
              " -0.039945293217897415,\n",
              " -0.04180648550391197,\n",
              " 0.010699075646698475,\n",
              " -0.08524954319000244,\n",
              " -0.012573327869176865,\n",
              " 0.02309892326593399,\n",
              " 0.046247418969869614,\n",
              " -0.012192013673484325,\n",
              " -0.015561694279313087,\n",
              " -0.012167183682322502,\n",
              " -0.0766274482011795,\n",
              " -0.007472001016139984,\n",
              " 0.0014517760137096047,\n",
              " 0.010383710265159607,\n",
              " -0.022133542224764824,\n",
              " 0.08529658615589142,\n",
              " 0.07960335165262222,\n",
              " 0.002138048643246293,\n",
              " -0.015356135554611683,\n",
              " -0.07043373584747314,\n",
              " -0.03440951183438301,\n",
              " -0.03737262636423111,\n",
              " -0.012660656124353409,\n",
              " -0.09012669324874878,\n",
              " -0.009611310437321663,\n",
              " 0.06629125028848648,\n",
              " -0.04951015114784241,\n",
              " 0.03815438598394394,\n",
              " 0.05591316148638725,\n",
              " -0.028328873217105865,\n",
              " 0.0023880801163613796,\n",
              " -0.07320185005664825,\n",
              " 0.054317016154527664,\n",
              " -0.05530431866645813,\n",
              " -0.011815153993666172,\n",
              " 0.02750193141400814,\n",
              " 0.021602176129817963,\n",
              " 0.04611603915691376,\n",
              " -0.007713329046964645,\n",
              " 0.0315704382956028,\n",
              " -0.007961170747876167,\n",
              " -0.02087210677564144,\n",
              " -0.03636317700147629,\n",
              " -0.04179048538208008,\n",
              " 0.07297632098197937,\n",
              " -0.02285842038691044,\n",
              " -0.02480371482670307,\n",
              " 0.024464230984449387,\n",
              " 0.036576297134160995,\n",
              " -0.005903571844100952,\n",
              " 0.06648729741573334,\n",
              " -0.018083572387695312,\n",
              " -0.00267703621648252,\n",
              " -0.0063590421341359615,\n",
              " -0.04291651397943497,\n",
              " -0.010632212273776531,\n",
              " -0.03768719360232353,\n",
              " 0.00920033548027277,\n",
              " 0.008991907350718975,\n",
              " -0.044379446655511856,\n",
              " -0.026100151240825653,\n",
              " -0.021125078201293945,\n",
              " 0.01377593819051981,\n",
              " 0.008183968253433704,\n",
              " -0.05843278765678406,\n",
              " -0.009043509140610695,\n",
              " -0.00038793025305494666,\n",
              " -0.0037606635596603155,\n",
              " -0.02848278544843197,\n",
              " -0.03973723575472832,\n",
              " -0.033635374158620834,\n",
              " -0.02306521311402321,\n",
              " 0.05993586406111717,\n",
              " -0.05296550691127777,\n",
              " -0.0060135368257761,\n",
              " -0.015808433294296265,\n",
              " -0.01709023118019104,\n",
              " -2.1874780941288918e-05,\n",
              " 0.011717270128428936,\n",
              " 0.07266660034656525,\n",
              " 0.022870948538184166,\n",
              " 0.054496653378009796,\n",
              " -0.029385050758719444,\n",
              " 0.04652747884392738,\n",
              " -0.023921139538288116,\n",
              " 0.005128944292664528,\n",
              " 0.01475225854665041,\n",
              " 0.026530683040618896,\n",
              " 0.049012988805770874,\n",
              " -0.03380497545003891,\n",
              " 0.03399384394288063,\n",
              " 0.03280828520655632,\n",
              " -0.058011554181575775,\n",
              " 0.013366165570914745,\n",
              " -0.0014724123757332563,\n",
              " -0.02065957896411419,\n",
              " 9.640788630349562e-05,\n",
              " 0.00941343791782856,\n",
              " -0.028971953317523003,\n",
              " -0.0737326443195343,\n",
              " 0.0272168330848217,\n",
              " 0.009813572280108929,\n",
              " -0.03423944488167763,\n",
              " 0.033431291580200195,\n",
              " -0.05820026248693466,\n",
              " -0.04637214541435242,\n",
              " -0.034600645303726196,\n",
              " 0.02209501340985298,\n",
              " 0.04326733946800232,\n",
              " 0.0077551379799842834,\n",
              " 0.07826302200555801,\n",
              " -0.03765697777271271,\n",
              " 0.01570536382496357,\n",
              " -0.02651839517056942,\n",
              " 0.017544973641633987,\n",
              " -0.045306019484996796,\n",
              " -0.007188236340880394,\n",
              " 0.030184756964445114,\n",
              " -0.027192372828722,\n",
              " -0.040726080536842346,\n",
              " -0.02009916864335537,\n",
              " -0.03881649672985077,\n",
              " -0.004546620883047581,\n",
              " -0.05784016102552414,\n",
              " -0.044924382120370865,\n",
              " -0.015380454249680042,\n",
              " -0.03641580045223236,\n",
              " 0.007476874627172947,\n",
              " 0.022227345034480095,\n",
              " 0.02140139602124691,\n",
              " 0.022165486589074135,\n",
              " -0.023798396810889244,\n",
              " 0.03500352427363396,\n",
              " -0.06388406455516815,\n",
              " 0.0017443906981498003,\n",
              " -0.073503278195858,\n",
              " 0.02395743876695633,\n",
              " -0.01074191927909851,\n",
              " 0.027907921001315117,\n",
              " 0.13946372270584106,\n",
              " 0.03730061650276184,\n",
              " -0.06988164782524109,\n",
              " -0.04699347913265228,\n",
              " 0.018221359699964523,\n",
              " -0.021977398544549942,\n",
              " -0.0037567743565887213,\n",
              " -0.03700833395123482,\n",
              " 0.06934913992881775,\n",
              " 0.06045270711183548,\n",
              " -0.00011745440860977396,\n",
              " -0.048087701201438904,\n",
              " 0.011701753363013268,\n",
              " 0.03979985788464546,\n",
              " -0.0649365708231926,\n",
              " -0.02038078010082245,\n",
              " -0.022207852452993393,\n",
              " -0.043025385588407516,\n",
              " -0.05890273675322533,\n",
              " 0.03202039748430252,\n",
              " -0.011841810308396816,\n",
              " 0.011044446378946304,\n",
              " -0.024068744853138924,\n",
              " 0.0014161489671096206,\n",
              " -0.006621872074902058,\n",
              " 0.03697248548269272,\n",
              " 0.0029102149419486523,\n",
              " -0.04175235703587532,\n",
              " 0.017671208828687668,\n",
              " 0.003038656897842884,\n",
              " 0.03596680983901024,\n",
              " -0.031439926475286484,\n",
              " 0.021212346851825714,\n",
              " 0.02699130028486252,\n",
              " -0.0407901406288147,\n",
              " -0.049329109489917755,\n",
              " 0.02311791107058525,\n",
              " 0.04758439585566521,\n",
              " 0.0044945962727069855,\n",
              " 0.013335054740309715,\n",
              " 0.025083789601922035,\n",
              " -0.024394607171416283,\n",
              " -0.0158438328653574,\n",
              " 0.08219940215349197,\n",
              " -0.0009921594755724072,\n",
              " 0.0015855395467951894,\n",
              " 0.022152315825223923,\n",
              " -0.0016592495376244187,\n",
              " 0.008997634053230286,\n",
              " 0.07010111957788467,\n",
              " 0.033816657960414886,\n",
              " 0.003992670215666294,\n",
              " -0.04037243500351906,\n",
              " 0.006260134279727936,\n",
              " 0.06567572802305222,\n",
              " -0.05656616389751434,\n",
              " 0.04634758085012436,\n",
              " 0.02412393130362034,\n",
              " -0.002525423187762499,\n",
              " -0.010457678698003292,\n",
              " 0.01208042073994875,\n",
              " -0.0025450249668210745,\n",
              " -0.010714762844145298,\n",
              " -0.07039342075586319,\n",
              " -0.00971139594912529,\n",
              " -0.0014800967182964087,\n",
              " 0.004230118356645107,\n",
              " -0.01982167363166809,\n",
              " -0.018555359914898872,\n",
              " -0.08707348257303238,\n",
              " -0.001826543128117919,\n",
              " -0.03611082211136818,\n",
              " -0.03354157134890556,\n",
              " 0.008374776691198349,\n",
              " 0.013814151287078857,\n",
              " -0.00022699535475112498,\n",
              " 0.039081644266843796,\n",
              " 0.07060854136943817,\n",
              " 0.01956300437450409,\n",
              " 0.015020228922367096,\n",
              " 0.003199291182681918,\n",
              " 0.011274749413132668,\n",
              " -0.025045400485396385,\n",
              " 0.037297457456588745,\n",
              " -0.01675480604171753,\n",
              " 0.024468261748552322,\n",
              " -0.018989529460668564,\n",
              " -0.002186301164329052,\n",
              " 0.018527118489146233,\n",
              " -0.017795221880078316,\n",
              " 0.06672007590532303,\n",
              " 0.036979008466005325,\n",
              " 0.0589771531522274,\n",
              " -0.020110683515667915,\n",
              " -0.0215122252702713,\n",
              " 0.006474520079791546,\n",
              " 0.03300005570054054,\n",
              " 0.006390468217432499,\n",
              " -0.02164328098297119,\n",
              " 0.033281855285167694,\n",
              " -0.001176962861791253,\n",
              " 0.022499341517686844,\n",
              " -0.060601331293582916,\n",
              " 0.013159317895770073,\n",
              " 0.03077774867415428,\n",
              " 0.09195946902036667,\n",
              " -0.06962361931800842,\n",
              " -0.011012065224349499,\n",
              " -0.026736725121736526,\n",
              " 0.022296082228422165,\n",
              " 0.021461939439177513,\n",
              " -0.04458160698413849,\n",
              " -0.009138599038124084,\n",
              " -0.018706930801272392,\n",
              " 0.01694430224597454,\n",
              " -0.032810602337121964,\n",
              " -0.015887783840298653,\n",
              " -0.036998070776462555,\n",
              " 0.02671159990131855,\n",
              " 0.015917327255010605,\n",
              " 0.039571069180965424,\n",
              " 0.044454507529735565,\n",
              " -0.02410287968814373,\n",
              " 0.03916733339428902,\n",
              " -0.03328029066324234,\n",
              " -0.013410987332463264,\n",
              " -0.021276233717799187,\n",
              " 0.04127465933561325,\n",
              " -0.020743390545248985,\n",
              " -0.061848316341638565,\n",
              " 0.03598998114466667,\n",
              " 0.026383865624666214,\n",
              " -0.06861855089664459,\n",
              " 0.002264944138005376,\n",
              " -0.014460728503763676,\n",
              " -0.0320044569671154,\n",
              " 0.01949469931423664,\n",
              " 0.007193371653556824,\n",
              " 0.059468504041433334,\n",
              " -0.016909120604395866,\n",
              " 0.02754037454724312,\n",
              " 0.008776141330599785,\n",
              " -0.0048073818907141685,\n",
              " -0.06688153743743896,\n",
              " 0.0719291940331459,\n",
              " 0.016504647210240364,\n",
              " -0.008657066151499748,\n",
              " -0.00953950546681881,\n",
              " 0.01559019461274147,\n",
              " -0.013831333257257938,\n",
              " 0.014289356768131256,\n",
              " -0.04016139358282089,\n",
              " 0.008838187903165817,\n",
              " 0.035840462893247604,\n",
              " -0.0019618121441453695,\n",
              " 0.054133687168359756,\n",
              " -0.04717834293842316,\n",
              " -0.0544406995177269,\n",
              " -0.020465539768338203,\n",
              " 0.09725676476955414,\n",
              " -0.0024923684541136026,\n",
              " 0.028866255655884743,\n",
              " -0.0006054036784917116,\n",
              " 0.011798640713095665,\n",
              " 0.04490991681814194,\n",
              " 0.06988256424665451,\n",
              " -0.025486532598733902,\n",
              " -0.012334373779594898,\n",
              " -0.016260208562016487,\n",
              " -0.009196960367262363,\n",
              " -0.047026511281728745,\n",
              " 0.04536621272563934,\n",
              " 0.045495904982089996,\n",
              " -0.0065522827208042145,\n",
              " -0.022502390667796135,\n",
              " 0.037823036313056946,\n",
              " -0.014935462735593319,\n",
              " 0.0150298485532403,\n",
              " -0.06472478061914444,\n",
              " 0.02000606060028076,\n",
              " 0.007965809665620327,\n",
              " -0.02028556913137436,\n",
              " -0.0034534772858023643,\n",
              " 0.0527801588177681,\n",
              " 0.02271394431591034,\n",
              " -0.0411255843937397,\n",
              " 0.007205003406852484,\n",
              " 0.043784718960523605,\n",
              " 0.002652136143296957,\n",
              " 0.024147536605596542,\n",
              " 0.0352587066590786,\n",
              " 0.005154719576239586,\n",
              " -0.026478290557861328,\n",
              " -0.021405480802059174,\n",
              " 0.03317221626639366,\n",
              " 0.021517327055335045,\n",
              " 0.03920222818851471,\n",
              " 0.03176013007760048,\n",
              " 0.05305273085832596,\n",
              " 0.07067427784204483,\n",
              " -0.020791180431842804,\n",
              " -0.02090391144156456,\n",
              " 0.03057437762618065,\n",
              " 0.01888769492506981,\n",
              " -0.022210532799363136,\n",
              " 0.013075260445475578,\n",
              " -0.02503841370344162,\n",
              " 0.0212718453258276,\n",
              " 0.012480495497584343,\n",
              " 0.014659550040960312,\n",
              " 0.022640781477093697,\n",
              " 0.012927072122693062,\n",
              " 0.07750986516475677,\n",
              " 0.013524283654987812,\n",
              " -0.016909265890717506,\n",
              " 0.04573788493871689,\n",
              " 0.014395006000995636,\n",
              " 0.05084885284304619,\n",
              " -0.000261490058619529,\n",
              " 0.0037096207961440086,\n",
              " 0.002382417442277074,\n",
              " 0.04448409378528595,\n",
              " 0.04862853139638901,\n",
              " 0.0215460192412138,\n",
              " -0.036940328776836395,\n",
              " 0.010835734196007252,\n",
              " -0.029288478195667267,\n",
              " -0.034191880375146866,\n",
              " -0.0017060908721759915,\n",
              " 0.04153389111161232,\n",
              " -0.03613046556711197,\n",
              " -0.014067520387470722,\n",
              " 0.05925287678837776,\n",
              " -0.018689744174480438,\n",
              " 0.005747530143707991,\n",
              " -0.013373570516705513,\n",
              " 0.03994647413492203,\n",
              " 0.03579731285572052,\n",
              " 0.01242211926728487,\n",
              " -0.05814000219106674,\n",
              " -0.039506878703832626,\n",
              " 0.008193631656467915,\n",
              " -0.04075198620557785,\n",
              " 0.022266030311584473,\n",
              " 0.058086954057216644,\n",
              " -0.007447078358381987,\n",
              " -0.04507588595151901,\n",
              " -0.04369109496474266,\n",
              " -0.02932460978627205,\n",
              " 0.008885865099728107,\n",
              " 0.040091387927532196,\n",
              " 0.017502205446362495,\n",
              " -0.04718175530433655,\n",
              " 0.04080284759402275,\n",
              " -0.011302901431918144,\n",
              " -0.02836526744067669,\n",
              " -0.00011795255704782903,\n",
              " -0.055508073419332504,\n",
              " 0.028690000995993614,\n",
              " -0.02963525429368019,\n",
              " -0.04837717115879059,\n",
              " 0.022130968049168587,\n",
              " -0.023107636719942093,\n",
              " 0.02893117442727089,\n",
              " 0.030466897413134575,\n",
              " 0.030279645696282387,\n",
              " 0.03496308997273445,\n",
              " 0.05922482907772064,\n",
              " 0.024002667516469955,\n",
              " -0.013470168225467205,\n",
              " 0.024791056290268898,\n",
              " 0.021919166669249535,\n",
              " 0.04663434252142906,\n",
              " 0.00019760924624279141,\n",
              " -0.04979453608393669,\n",
              " 0.004187639337033033,\n",
              " -0.014505494385957718,\n",
              " -0.009464165195822716,\n",
              " -0.0006209489656612277,\n",
              " 0.006865257862955332,\n",
              " 0.01830698736011982,\n",
              " 0.0664939135313034,\n",
              " -0.007858195342123508,\n",
              " 0.021244436502456665,\n",
              " 0.011607942171394825,\n",
              " 0.024272777140140533,\n",
              " -0.01703466847538948,\n",
              " 0.030969327315688133,\n",
              " 0.06683583557605743,\n",
              " 0.02883134037256241,\n",
              " 0.03655090555548668,\n",
              " 0.0039057487156242132,\n",
              " 0.050540778785943985,\n",
              " 0.02412077970802784,\n",
              " -0.014356346800923347,\n",
              " 0.05860397592186928,\n",
              " 0.07242055237293243,\n",
              " -0.02753409370779991,\n",
              " -0.02364381030201912,\n",
              " 0.04670720547437668,\n",
              " 0.06369748711585999,\n",
              " 0.004552707076072693,\n",
              " 0.0995810255408287,\n",
              " 0.021902013570070267,\n",
              " -0.0030878796242177486,\n",
              " 0.0068237450905144215,\n",
              " -0.03704532980918884,\n",
              " 0.007008297368884087,\n",
              " -0.05545720458030701,\n",
              " 0.04909360036253929,\n",
              " 0.026529639959335327,\n",
              " -0.0346694141626358,\n",
              " 0.027634212747216225,\n",
              " 0.015151522122323513,\n",
              " -0.030954835936427116,\n",
              " 0.01754775457084179,\n",
              " 0.01770191267132759,\n",
              " -0.013504200614988804,\n",
              " 0.025946427136659622,\n",
              " 0.013629470951855183,\n",
              " -0.005425794515758753,\n",
              " 0.010614718310534954,\n",
              " -0.0015319398371502757,\n",
              " 0.038094792515039444,\n",
              " 0.015155342407524586,\n",
              " -0.03947481885552406,\n",
              " 0.029109004884958267,\n",
              " 0.038553185760974884,\n",
              " 0.0013215598883107305,\n",
              " -0.02590908110141754,\n",
              " -0.02878399007022381,\n",
              " -0.006192055996507406,\n",
              " -0.03492344170808792,\n",
              " -0.02450043149292469,\n",
              " -0.0382344089448452,\n",
              " 0.07043585926294327,\n",
              " -0.02185794711112976,\n",
              " -0.02648184821009636,\n",
              " 0.014079077169299126,\n",
              " 1.7020025552483276e-05,\n",
              " -0.0035027912817895412,\n",
              " 0.051689084619283676,\n",
              " -0.04909846559166908,\n",
              " 0.011308024637401104,\n",
              " 0.0262058824300766,\n",
              " 0.007503950037062168,\n",
              " -0.08388341963291168,\n",
              " 0.016999533399939537,\n",
              " 0.018419619649648666,\n",
              " -0.05702647566795349,\n",
              " 0.028616877272725105,\n",
              " 0.01110485102981329,\n",
              " 0.0487791933119297,\n",
              " -0.0818999856710434,\n",
              " 0.002655185991898179,\n",
              " 0.020519569516181946,\n",
              " 0.009464774280786514,\n",
              " 0.027700262144207954,\n",
              " -0.06020333245396614,\n",
              " -0.026564741507172585,\n",
              " -0.03010314516723156,\n",
              " 0.00458727590739727,\n",
              " -0.028598397970199585,\n",
              " 0.0007253923686221242,\n",
              " 0.044076647609472275,\n",
              " -0.014686034061014652,\n",
              " 0.010321375913918018,\n",
              " -0.10567240417003632,\n",
              " 0.014254678972065449,\n",
              " -0.05442153289914131,\n",
              " 0.020131055265665054,\n",
              " 0.03207854926586151,\n",
              " 0.006493283435702324,\n",
              " -8.058997627813369e-05,\n",
              " 0.04034598544239998,\n",
              " 0.054774533957242966,\n",
              " 0.053106170147657394,\n",
              " -0.06814957410097122,\n",
              " 0.010697842575609684,\n",
              " -0.040475040674209595,\n",
              " 0.008675497025251389,\n",
              " -0.013909435831010342,\n",
              " 0.023953856900334358,\n",
              " -0.03938881307840347,\n",
              " 0.01857720874249935,\n",
              " 0.040306299924850464,\n",
              " -0.01632242277264595,\n",
              " -0.01115192100405693,\n",
              " 0.029489953070878983,\n",
              " -0.04912535473704338,\n",
              " -0.03594864904880524,\n",
              " 0.03490805998444557,\n",
              " -0.014499329961836338,\n",
              " 0.00987993273884058,\n",
              " 0.015104111284017563,\n",
              " -0.04515864700078964,\n",
              " 0.08251923322677612,\n",
              " -0.04121609777212143,\n",
              " 0.10399515181779861,\n",
              " -0.0008364097448065877,\n",
              " -0.025716878473758698,\n",
              " 0.050898969173431396,\n",
              " 0.015330437570810318,\n",
              " 0.0011878544464707375,\n",
              " 0.016823649406433105,\n",
              " 0.00013095559552311897,\n",
              " 0.019026093184947968,\n",
              " 0.03501054272055626,\n",
              " 0.007486838847398758,\n",
              " -0.034481246024370193,\n",
              " -0.04874048009514809,\n",
              " 0.040747273713350296,\n",
              " -0.01908840984106064,\n",
              " 0.02022647298872471,\n",
              " -0.0009105517528951168,\n",
              " 0.02005535550415516,\n",
              " -0.006273913197219372,\n",
              " -0.029840964823961258,\n",
              " 0.030133333057165146,\n",
              " -0.014037856832146645,\n",
              " -0.001469410490244627,\n",
              " 0.0026587073225528,\n",
              " 0.005965273827314377,\n",
              " -0.022571230307221413,\n",
              " 0.06250502914190292,\n",
              " 0.046498075127601624,\n",
              " 0.007142454385757446,\n",
              " -0.014344950206577778,\n",
              " 0.013906982727348804,\n",
              " 0.003913061693310738,\n",
              " -0.006548486649990082,\n",
              " 0.0017414749599993229,\n",
              " 0.029849335551261902,\n",
              " 0.024426771327853203,\n",
              " -0.012563960626721382,\n",
              " 0.017205489799380302,\n",
              " -0.02139156498014927,\n",
              " -0.03744542971253395,\n",
              " -0.019764497876167297,\n",
              " 0.08523226529359818,\n",
              " -0.04003520309925079,\n",
              " 0.02579677663743496,\n",
              " -0.014984124340116978,\n",
              " -0.030986100435256958,\n",
              " -0.0524042472243309,\n",
              " -0.012023044750094414,\n",
              " -0.026166368275880814,\n",
              " 0.04099416732788086,\n",
              " 0.04497910290956497,\n",
              " -0.042102646082639694,\n",
              " 0.01121737714856863,\n",
              " 0.0014244945487007499,\n",
              " -0.08299601823091507,\n",
              " -0.037080902606248856,\n",
              " 0.0026240136940032244,\n",
              " -0.06959893554449081,\n",
              " 0.010822482407093048,\n",
              " 0.08774671703577042,\n",
              " 0.008841004222631454,\n",
              " 0.009496107697486877,\n",
              " -0.037352290004491806,\n",
              " -0.04915885254740715,\n",
              " 0.011412392370402813,\n",
              " 0.01210357341915369,\n",
              " 0.004640300292521715,\n",
              " 0.029400832951068878,\n",
              " 0.03648070618510246,\n",
              " -0.028180893510580063,\n",
              " 0.010763821192085743,\n",
              " 0.04865449666976929,\n",
              " -0.005209042690694332,\n",
              " 0.04590819403529167,\n",
              " 0.060524869710206985,\n",
              " 0.015516949817538261,\n",
              " -0.038346052169799805,\n",
              " -0.0054349456913769245,\n",
              " 0.03699217736721039,\n",
              " 0.05232878029346466,\n",
              " -0.0033194476272910833,\n",
              " -0.009654871188104153,\n",
              " -0.009326612576842308,\n",
              " -0.02085983380675316,\n",
              " 0.045742008835077286,\n",
              " 0.07586044818162918,\n",
              " -0.02147483266890049,\n",
              " -0.012182612903416157,\n",
              " 0.011786649003624916,\n",
              " 6.679219950456172e-05,\n",
              " -0.01565036177635193,\n",
              " -0.025331012904644012,\n",
              " 0.0002790024736896157,\n",
              " 0.02563965506851673,\n",
              " -0.03222601115703583,\n",
              " 0.0063233026303350925,\n",
              " -0.016894996166229248,\n",
              " 0.00833852682262659,\n",
              " -0.04985398054122925,\n",
              " 0.02656537853181362,\n",
              " -0.02746446058154106,\n",
              " -0.04541788622736931,\n",
              " -0.017379462718963623,\n",
              " -0.06607503443956375,\n",
              " -0.018424198031425476,\n",
              " -0.08135224133729935,\n",
              " 0.01582079380750656,\n",
              " -0.03265051171183586,\n",
              " 0.02658158913254738,\n",
              " 0.0003634286404121667,\n",
              " -0.05284392088651657,\n",
              " -0.010262387804687023,\n",
              " 0.010587421245872974,\n",
              " 0.002038296777755022,\n",
              " 0.033618226647377014,\n",
              " -0.03411681577563286,\n",
              " 0.06786651164293289,\n",
              " -0.01906300149857998,\n",
              " 0.00323424837552011,\n",
              " -0.04437381774187088,\n",
              " 0.008844339288771152,\n",
              " 0.021817639470100403,\n",
              " 0.029185136780142784]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.embed_query(\"Tell me about Life\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifSaPvfMGM1g",
        "outputId": "6aa62579-7b89-41ba-bb52-50b954031665"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embeddings.embed_query(\"Tell me about Life\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtv5-cleF4QH",
        "outputId": "00ad5fd5-89ea-40fc-e31e-543f2b098fe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.017449533566832542,\n",
              " 0.00423057284206152,\n",
              " -0.01623031683266163,\n",
              " -0.016505029052495956,\n",
              " -0.06461256742477417]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings.embed_query(\"Tell me about Life\")[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TyIBtRrTIFne"
      },
      "outputs": [],
      "source": [
        "from langchain_chroma import Chroma\n",
        "vectorstore = Chroma.from_documents(\n",
        "    documents = [document_1, document_2, document_3, document_4, document_5, document_6, document_7, document_8, document_9, document_10],\n",
        "    embedding = embeddings\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "toGIxFQqIsxR",
        "outputId": "1b9fde0a-95ee-4257-9086-660301f1eb41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['_Chroma__ensure_collection',\n",
              " '_Chroma__query_collection',\n",
              " '_LANGCHAIN_DEFAULT_COLLECTION_NAME',\n",
              " '__abstractmethods__',\n",
              " '__annotations__',\n",
              " '__class__',\n",
              " '__delattr__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getstate__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__le__',\n",
              " '__lt__',\n",
              " '__module__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__setattr__',\n",
              " '__sizeof__',\n",
              " '__slots__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " '__weakref__',\n",
              " '_abc_impl',\n",
              " '_asimilarity_search_with_relevance_scores',\n",
              " '_chroma_collection',\n",
              " '_client',\n",
              " '_client_settings',\n",
              " '_collection',\n",
              " '_collection_metadata',\n",
              " '_collection_name',\n",
              " '_cosine_relevance_score_fn',\n",
              " '_embedding_function',\n",
              " '_euclidean_relevance_score_fn',\n",
              " '_get_retriever_tags',\n",
              " '_max_inner_product_relevance_score_fn',\n",
              " '_persist_directory',\n",
              " '_select_relevance_score_fn',\n",
              " '_similarity_search_with_relevance_scores',\n",
              " 'aadd_documents',\n",
              " 'aadd_texts',\n",
              " 'add_documents',\n",
              " 'add_images',\n",
              " 'add_texts',\n",
              " 'adelete',\n",
              " 'afrom_documents',\n",
              " 'afrom_texts',\n",
              " 'aget_by_ids',\n",
              " 'amax_marginal_relevance_search',\n",
              " 'amax_marginal_relevance_search_by_vector',\n",
              " 'as_retriever',\n",
              " 'asearch',\n",
              " 'asimilarity_search',\n",
              " 'asimilarity_search_by_vector',\n",
              " 'asimilarity_search_with_relevance_scores',\n",
              " 'asimilarity_search_with_score',\n",
              " 'delete',\n",
              " 'delete_collection',\n",
              " 'embeddings',\n",
              " 'encode_image',\n",
              " 'from_documents',\n",
              " 'from_texts',\n",
              " 'get',\n",
              " 'get_by_ids',\n",
              " 'max_marginal_relevance_search',\n",
              " 'max_marginal_relevance_search_by_vector',\n",
              " 'override_relevance_score_fn',\n",
              " 'reset_collection',\n",
              " 'search',\n",
              " 'similarity_search',\n",
              " 'similarity_search_by_image',\n",
              " 'similarity_search_by_image_with_relevance_score',\n",
              " 'similarity_search_by_vector',\n",
              " 'similarity_search_by_vector_with_relevance_scores',\n",
              " 'similarity_search_with_relevance_scores',\n",
              " 'similarity_search_with_score',\n",
              " 'similarity_search_with_vectors',\n",
              " 'update_document',\n",
              " 'update_documents']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dir(vectorstore)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-vN9X40J-3N",
        "outputId": "f819f858-b699-4f69-e3fb-fbddc3bda705"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain_chroma.vectorstores.Chroma at 0x7e764853cf10>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmPYjZGkKMW_",
        "outputId": "8eccdf47-f09c-4a2d-f157-90389457acf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='3bd1d6c5-060e-4788-8ad7-8a2e2a8ef7b1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
              " Document(id='81fe973a-ac7e-47ef-a718-5ed0902f6b5b', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='0d7f4d7f-2f08-42b3-83c6-02e5fed2cc81', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
              " Document(id='170621fc-21fd-49e5-b28d-0b1ace3c41ac', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\")]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search(\"Tell me about the LangGraph\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FAJlXc6LjWC",
        "outputId": "4d699fb0-c50a-4006-83e7-b325ffc5628f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='3bd1d6c5-060e-4788-8ad7-8a2e2a8ef7b1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
              " Document(id='81fe973a-ac7e-47ef-a718-5ed0902f6b5b', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='0d7f4d7f-2f08-42b3-83c6-02e5fed2cc81', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
              " Document(id='170621fc-21fd-49e5-b28d-0b1ace3c41ac', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\")]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await vectorstore.asimilarity_search(\"Tell me about the LangGraph\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEQBFLvCN7h3",
        "outputId": "e5d0eb93-5583-44aa-b171-6c55ad95be0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(Document(id='3bd1d6c5-060e-4788-8ad7-8a2e2a8ef7b1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
              "  0.6261429190635681),\n",
              " (Document(id='81fe973a-ac7e-47ef-a718-5ed0902f6b5b', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              "  0.8392366170883179),\n",
              " (Document(id='0d7f4d7f-2f08-42b3-83c6-02e5fed2cc81', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
              "  1.2234234809875488),\n",
              " (Document(id='170621fc-21fd-49e5-b28d-0b1ace3c41ac', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              "  1.2270199060440063)]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectorstore.similarity_search_with_score(\"Tell me about the LangGraph\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3dd927mOyfv",
        "outputId": "cf999141-fe22-482c-bcb3-7ab6af318656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(id='3bd1d6c5-060e-4788-8ad7-8a2e2a8ef7b1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
              " Document(id='81fe973a-ac7e-47ef-a718-5ed0902f6b5b', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
              " Document(id='170621fc-21fd-49e5-b28d-0b1ace3c41ac', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
              " Document(id='0d7f4d7f-2f08-42b3-83c6-02e5fed2cc81', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding = embeddings.embed_query(\"Tell me about the LangGaraph\")\n",
        "vectorstore.similarity_search_by_vector(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0Mkh9L4Ptz5",
        "outputId": "bca7313a-4c52-4642-dd37-72b2def99a05"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.01932417042553425,\n",
              " 0.04753834381699562,\n",
              " -0.059654898941516876,\n",
              " 0.015970952808856964,\n",
              " -0.014183997176587582,\n",
              " -0.005225215572863817,\n",
              " 0.004861144348978996,\n",
              " -0.013530859723687172,\n",
              " 0.06214635819196701,\n",
              " 0.08037451654672623]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embedding[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cq4Z4PeePJhW",
        "outputId": "1f18f43d-e2e5-413f-c0b0-ef6b0d17f046"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFI_U0BFcDvj",
        "outputId": "7c124b2b-cf5b-488f-d200-545547c74d41"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[[Document(id='3bd1d6c5-060e-4788-8ad7-8a2e2a8ef7b1', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!')]]"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "retrieve = RunnableLambda(vectorstore.similarity_search).bind(k=1)\n",
        "retrieve.batch([\"LangGraph\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpHnXSMJlDYX"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model = \"gemini-1.5-flash\",\n",
        "    temperature = 1.0,\n",
        "    api_key = userdata.get('GOOGLE_API_KEY')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EASSirkBLI_5",
        "outputId": "939297ce-c738-4913-eb59-973ab0613cf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Allama Muhammad Iqbal (1877-1938) was a highly influential poet, philosopher, and political thinker from the Indian subcontinent.  He is considered one of the most important figures in Urdu and Persian literature, and his work had a profound impact on the Muslim movements leading up to the creation of Pakistan.\\n\\nHere are some key aspects of his life and contributions:\\n\\n* **Literary Genius:** Iqbal's poetry, both in Urdu and Persian, is characterized by its depth, philosophical complexity, and powerful imagery.  His poems are not merely romantic or lyrical; they delve into the human condition, exploring themes of self-realization, spirituality, and the socio-political realities of his time.  Key works include *Asrar-e-Khudi* (Secrets of the Self), *Rumuz-e-Bekhudi* (Mysteries of Selflessness), *Payam-e-Mashriq* (Message from the East), and *Bal-e-Jibril* (Gabriel's Wing) in Persian, and *Bang-e-Dara* (The Call of the Marching Bell) and *Zarb-e-Kaleem* (The Stroke of Moses's Staff) in Urdu.\\n\\n* **Philosophical Depth:** Iqbal was deeply influenced by various philosophical traditions, including Sufism, idealism, and Western thought.  He synthesized these influences to create his unique philosophical system, which emphasized the importance of self-awareness (khudi), striving for excellence (mard-e-momin), and the need for a strong moral character. His philosophy stressed the importance of action and the pursuit of a higher purpose in life.\\n\\n* **Political Activism:** Iqbal's poetry and speeches played a crucial role in shaping the political consciousness of Muslims in the Indian subcontinent. He advocated for a separate Muslim state, believing that Muslims needed their own homeland to protect their cultural and religious identity. His famous address at the 1930 Allahabad session of the Muslim League, where he articulated his vision for a separate Muslim state, is considered a landmark event in the history of Pakistan Movement.\\n\\n* **Advocate for Islamic Modernism:** Iqbal was a staunch advocate for a revitalized Islam, one that could reconcile faith with modernity. He believed that Muslims needed to reclaim their intellectual and political agency and engage with the challenges of the modern world.  He didn't advocate for a return to a rigid past, but rather for a dynamic interpretation of Islamic principles that could address contemporary issues.\\n\\n* **Enduring Legacy:** Iqbal's legacy extends far beyond his lifetime. He is revered as a national poet in Pakistan, and his works are studied and celebrated across the Muslim world. His ideas continue to inspire political and intellectual debate, and his poetry remains a source of inspiration and guidance for many.  His emphasis on self-reliance, moral courage, and the pursuit of higher ideals continues to resonate with people across diverse backgrounds.\\n\\nIn short, Allama Iqbal was a multifaceted genius who made significant contributions to literature, philosophy, and politics.  His life and work are a testament to the power of intellectual engagement and the importance of striving for a better future.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run-e53d54a0-2ce2-4bab-8c0d-b54e33efe61b-0', usage_metadata={'input_tokens': 6, 'output_tokens': 653, 'total_tokens': 659, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm.invoke(\"Tell me about Allama Iqbal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moZM3PwhoofA"
      },
      "source": [
        "#**AUGMENTATION**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MwCTok4El_v7"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "message = \"\"\"\n",
        "Answer this questoin using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRnJFBtA-1yR"
      },
      "outputs": [],
      "source": [
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxoYPhzL_hdX"
      },
      "source": [
        "#**RAG**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "auE8eAmzDAQG"
      },
      "outputs": [],
      "source": [
        "from langchain_core.runnables import RunnableMap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "geMaCzcIEUID"
      },
      "outputs": [],
      "source": [
        "rag_chain = RunnableMap({\n",
        "    \"context\": retrieve,\n",
        "    \"question\": RunnableLambda(lambda x: x)           # Wrap the question in a RunnableLambda to make it callable\n",
        "}) | prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjXh7LtnB3kq",
        "outputId": "bcc3b76c-d0ee-447f-d5cd-753037d9523f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The provided text does not contain any information about Quaid-e-Azam.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke(\"Tell me about Quaid e Azam\")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vLQPFcYEfpC",
        "outputId": "9ae61b28-acad-4c58-bf63-55614663d4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided text, LangGraph is a framework for building stateful, agentic applications.\n"
          ]
        }
      ],
      "source": [
        "response = rag_chain.invoke(\"Tell me about LangGraph\")\n",
        "print(response.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMuIIU/e1ItREY2YiGyHTSM",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
